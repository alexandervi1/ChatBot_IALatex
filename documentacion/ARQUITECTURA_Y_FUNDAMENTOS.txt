================================================================================
              CHATBOT IA CON COPILOTO LATEX - ARQUITECTURA Y FUNDAMENTOS
                          Documento TÃ©cnico para Defensa
                                VersiÃ³n 4.1.1
================================================================================

ÃNDICE
------
1. IntroducciÃ³n y VisiÃ³n General
2. Arquitectura del Sistema
3. Patrones de DiseÃ±o Implementados
4. Backend: FastAPI y Python
5. Sistema RAG (Retrieval-Augmented Generation)
6. Proveedores de Inteligencia Artificial
7. Base de Datos y Almacenamiento Vectorial
8. Sistema de CachÃ© con Redis
9. Procesamiento AsÃ­ncrono con Celery
10. Frontend: Next.js y React
11. Sistema de AutenticaciÃ³n y Seguridad
12. Editor LaTeX con Monaco
13. ContenedorizaciÃ³n con Docker
14. Testing y Calidad de CÃ³digo
15. MÃ©tricas y Observabilidad
16. Glosario de TÃ©rminos TÃ©cnicos

================================================================================
1. INTRODUCCIÃ“N Y VISIÃ“N GENERAL
================================================================================

1.1 Â¿QUÃ‰ ES ESTE SISTEMA?
-------------------------
Este sistema es un chatbot acadÃ©mico inteligente que permite a los usuarios:
- Subir documentos (PDF, Word, TXT, PowerPoint)
- Hacer preguntas sobre el contenido de esos documentos
- Recibir respuestas generadas por IA basadas en el contenido real
- Editar documentos LaTeX con asistencia de IA

1.2 PROBLEMA QUE RESUELVE
-------------------------
Los estudiantes e investigadores a menudo tienen grandes cantidades de documentos
que necesitan consultar. Leer todo manualmente es ineficiente. Este sistema:
- Indexa automÃ¡ticamente el contenido de los documentos
- Permite consultas en lenguaje natural
- Genera respuestas citando las fuentes originales
- Asiste en la redacciÃ³n de documentos acadÃ©micos

1.3 TECNOLOGÃAS PRINCIPALES
---------------------------
BACKEND:
- Python 3.11+
- FastAPI (framework web asÃ­ncrono)
- SQLAlchemy (ORM para base de datos)
- Celery (procesamiento en segundo plano)

FRONTEND:
- Next.js 15 (framework React)
- React 19
- TypeScript
- Tailwind CSS

INFRAESTRUCTURA:
- Docker (contenedorizaciÃ³n)
- PostgreSQL + pgvector (base de datos vectorial)
- Redis (cachÃ© y cola de mensajes)


================================================================================
2. ARQUITECTURA DEL SISTEMA
================================================================================

2.1 ARQUITECTURA DE MICROSERVICIOS
----------------------------------
El sistema sigue una arquitectura de microservicios donde cada componente
es independiente y se comunica a travÃ©s de APIs y colas de mensajes.

DIAGRAMA DE ARQUITECTURA:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FRONTEND (Puerto 3000)                  â”‚
â”‚                         Next.js 15                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚    Chat     â”‚  â”‚   Copilot   â”‚  â”‚      Admin      â”‚    â”‚
â”‚   â”‚   Layout    â”‚  â”‚   Editor    â”‚  â”‚     Panel       â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ HTTP / Server-Sent Events
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     BACKEND (Puerto 8000)                   â”‚
â”‚                         FastAPI                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  Auth   â”‚  â”‚  Chat   â”‚  â”‚  Docs   â”‚  â”‚   Admin     â”‚   â”‚
â”‚   â”‚ Router  â”‚  â”‚ Router  â”‚  â”‚ Router  â”‚  â”‚   Router    â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                         â”‚                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚                  SERVICIOS                         â”‚    â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚   â”‚  â”‚ AI Prov. â”‚  â”‚  Search  â”‚  â”‚    Embeddings    â”‚ â”‚    â”‚
â”‚   â”‚  â”‚ Manager  â”‚  â”‚  Engine  â”‚  â”‚     (Cached)     â”‚ â”‚    â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚            â”‚            â”‚             â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚   DB    â”‚  â”‚  Redis  â”‚  â”‚ Celery  â”‚
   â”‚  5432   â”‚  â”‚  6379   â”‚  â”‚ Worker  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   PostgreSQL     Cache        Async
   + pgvector    + Queue       Tasks

2.2 FLUJO DE DATOS
------------------
1. Usuario sube documento â†’ Frontend envÃ­a a Backend
2. Backend procesa documento â†’ Celery (async) extrae texto
3. Texto se divide en "chunks" â†’ Se generan embeddings (vectores)
4. Embeddings se almacenan en PostgreSQL + pgvector
5. Usuario hace pregunta â†’ Backend busca chunks relevantes
6. Chunks relevantes + pregunta â†’ IA genera respuesta
7. Respuesta se envÃ­a al frontend en streaming

2.3 SEPARACIÃ“N DE RESPONSABILIDADES
-----------------------------------
Cada capa tiene una responsabilidad especÃ­fica:

CAPA DE PRESENTACIÃ“N (Frontend):
- Renderizado de UI
- Manejo de estado local
- ValidaciÃ³n de formularios
- ComunicaciÃ³n con API

CAPA DE API (Routers):
- Endpoints HTTP
- ValidaciÃ³n de requests
- AutenticaciÃ³n/AutorizaciÃ³n
- SerializaciÃ³n de respuestas

CAPA DE SERVICIOS:
- LÃ³gica de negocio
- OrquestaciÃ³n de operaciones
- IntegraciÃ³n con proveedores externos

CAPA DE DATOS:
- Modelos ORM
- Queries a base de datos
- CachÃ©

================================================================================
3. PATRONES DE DISEÃ‘O IMPLEMENTADOS
================================================================================

3.1 PATRÃ“N STRATEGY (Proveedores de IA)
---------------------------------------
QUÃ‰ ES: Permite definir una familia de algoritmos intercambiables.

IMPLEMENTACIÃ“N:
- Clase abstracta: AIProvider
- Implementaciones concretas: GeminiProvider, OpenAIProvider, AnthropicProvider

BENEFICIO: Se puede cambiar el proveedor de IA sin modificar el cÃ³digo que lo usa.

CÃ“DIGO (simplificado):
```python
class AIProvider(ABC):
    @abstractmethod
    def generate_stream(self, prompt, api_key, ...):
        pass

class GeminiProvider(AIProvider):
    def generate_stream(self, prompt, api_key, ...):
        # ImplementaciÃ³n especÃ­fica de Gemini

class OpenAIProvider(AIProvider):
    def generate_stream(self, prompt, api_key, ...):
        # ImplementaciÃ³n especÃ­fica de OpenAI
```

3.2 PATRÃ“N REPOSITORY (Acceso a Datos)
--------------------------------------
QUÃ‰ ES: Abstrae la lÃ³gica de acceso a datos del resto de la aplicaciÃ³n.

IMPLEMENTACIÃ“N:
- Modelos SQLAlchemy definen la estructura
- Queries se encapsulan en funciones de servicio
- El cÃ³digo de negocio no conoce detalles de SQL

BENEFICIO: Facilita testing y cambio de base de datos.

3.3 PATRÃ“N FACTORY (CreaciÃ³n de Objetos)
----------------------------------------
QUÃ‰ ES: Centraliza la creaciÃ³n de objetos complejos.

IMPLEMENTACIÃ“N:
- AIProviderManager crea el proveedor correcto segÃºn el ID
- get_db() crea sesiones de base de datos

3.4 PATRÃ“N DECORATOR (Middleware)
---------------------------------
QUÃ‰ ES: AÃ±ade funcionalidad a objetos sin modificarlos.

IMPLEMENTACIÃ“N:
- Rate limiting como middleware
- Logging como decorador
- AutenticaciÃ³n como dependencia

3.5 PATRÃ“N OBSERVER (Eventos)
-----------------------------
QUÃ‰ ES: Objetos notifican cambios a otros objetos interesados.

IMPLEMENTACIÃ“N:
- WebSocket para notificaciones en tiempo real
- Redis Pub/Sub para comunicaciÃ³n entre servicios

3.6 PATRÃ“N SINGLETON (Instancias Ãšnicas)
----------------------------------------
QUÃ‰ ES: Garantiza una Ãºnica instancia de una clase.

IMPLEMENTACIÃ“N:
- SearchEngine: una sola instancia con modelo CrossEncoder cargado
- Redis connection pool

================================================================================
4. BACKEND: FASTAPI Y PYTHON
================================================================================

4.1 Â¿POR QUÃ‰ FASTAPI?
---------------------
FastAPI es un framework web moderno para Python con:
- ALTO RENDIMIENTO: Basado en Starlette (async), comparable a Node.js
- TIPADO: Usa type hints de Python para validaciÃ³n automÃ¡tica
- DOCUMENTACIÃ“N: Genera OpenAPI/Swagger automÃ¡ticamente
- ASYNC NATIVO: Soporta async/await para operaciones I/O

4.2 ESTRUCTURA DEL BACKEND
--------------------------
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Punto de entrada, configuraciÃ³n de app
â”‚   â”œâ”€â”€ routers/             # Endpoints organizados por recurso
â”‚   â”‚   â”œâ”€â”€ auth.py          # Login, registro, tokens
â”‚   â”‚   â”œâ”€â”€ chat.py          # BÃºsqueda y respuestas IA
â”‚   â”‚   â”œâ”€â”€ documents.py     # CRUD de documentos
â”‚   â”‚   â”œâ”€â”€ admin.py         # Operaciones administrativas
â”‚   â”‚   â””â”€â”€ providers.py     # Listado de proveedores IA
â”‚   â”œâ”€â”€ dependencies.py      # InyecciÃ³n de dependencias
â”‚   â”œâ”€â”€ metrics.py           # MÃ©tricas Prometheus
â”‚   â””â”€â”€ rate_limiter.py      # LÃ­mites de peticiones
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ai_providers.py      # AbstracciÃ³n de proveedores IA
â”‚   â”œâ”€â”€ search_engine.py     # Motor de bÃºsqueda RAG
â”‚   â”œâ”€â”€ embedding_system.py  # GeneraciÃ³n de embeddings
â”‚   â”œâ”€â”€ auth_service.py      # LÃ³gica de autenticaciÃ³n
â”‚   â”œâ”€â”€ audit_service.py     # Registro de auditorÃ­a
â”‚   â””â”€â”€ pdf_processor.py     # ExtracciÃ³n de texto
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ connection.py        # ConfiguraciÃ³n de conexiÃ³n
â”‚   â””â”€â”€ models.py            # Modelos ORM
â””â”€â”€ utils/
    â””â”€â”€ encryption.py        # EncriptaciÃ³n de API keys

4.3 INYECCIÃ“N DE DEPENDENCIAS
-----------------------------
FastAPI usa un sistema de inyecciÃ³n de dependencias que permite:
- Compartir recursos entre endpoints
- Testing mÃ¡s fÃ¡cil (se pueden inyectar mocks)
- CÃ³digo mÃ¡s limpio y modular

EJEMPLO:
```python
@router.get("/documents")
async def get_documents(
    db: Session = Depends(get_db),  # Inyecta sesiÃ³n de DB
    user: User = Depends(get_current_user)  # Inyecta usuario autenticado
):
    return db.query(Document).filter(Document.owner_id == user.id).all()
```

4.4 MANEJO DE ERRORES
---------------------
Se implementa un sistema centralizado de excepciones:
- Excepciones personalizadas por tipo de error
- Handler global que convierte excepciones a respuestas HTTP
- Logging estructurado de errores

================================================================================
5. SISTEMA RAG (RETRIEVAL-AUGMENTED GENERATION)
================================================================================

5.1 Â¿QUÃ‰ ES RAG?
----------------
RAG es una tÃ©cnica que combina:
- RETRIEVAL: Buscar informaciÃ³n relevante en una base de conocimiento
- AUGMENTED: Usar esa informaciÃ³n para enriquecer el prompt
- GENERATION: Generar una respuesta usando un modelo de lenguaje

VENTAJAS SOBRE LLM PURO:
- Respuestas basadas en datos reales (no inventados)
- Fuentes verificables y citables
- Conocimiento actualizado (no limitado al entrenamiento del modelo)

5.2 PIPELINE RAG IMPLEMENTADO
-----------------------------

PASO 1: INGESTA DE DOCUMENTOS
-----------------------------
1. Usuario sube archivo (PDF, DOCX, TXT, PPTX)
2. Se extrae el texto plano usando librerÃ­as especializadas:
   - PDF: PyPDF2
   - Word: python-docx
   - PowerPoint: python-pptx

PASO 2: CHUNKING (DIVISIÃ“N EN FRAGMENTOS)
-----------------------------------------
El texto se divide en fragmentos manejables porque:
- Los modelos tienen lÃ­mite de contexto
- Fragmentos pequeÃ±os son mÃ¡s precisos para bÃºsqueda

CONFIGURACIÃ“N:
- TamaÃ±o de chunk: ~500 caracteres
- Overlap (solapamiento): ~100 caracteres

Â¿POR QUÃ‰ OVERLAP?
Para no cortar ideas a la mitad. El solapamiento garantiza que una oraciÃ³n
que empieza en un chunk continÃºe en el siguiente.

PASO 3: GENERACIÃ“N DE EMBEDDINGS
--------------------------------
Â¿QUÃ‰ ES UN EMBEDDING?
Es una representaciÃ³n numÃ©rica (vector) del significado semÃ¡ntico del texto.

MODELO USADO: all-MiniLM-L6-v2
- DimensiÃ³n: 384
- TamaÃ±o: ~80MB
- Velocidad: Muy rÃ¡pido

CÃ“MO FUNCIONA:
"El perro corre en el parque" â†’ [0.123, -0.456, 0.789, ..., 0.012] (384 nÃºmeros)

Textos con significado similar tienen vectores similares (distancia coseno baja).

PASO 4: ALMACENAMIENTO EN BASE DE DATOS VECTORIAL
-------------------------------------------------
Los embeddings se almacenan en PostgreSQL con la extensiÃ³n pgvector.

Â¿QUÃ‰ ES PGVECTOR?
Es una extensiÃ³n de PostgreSQL que permite:
- Almacenar vectores como tipo de datos nativo
- Realizar bÃºsquedas de similitud eficientes
- Usar Ã­ndices especializados (IVFFlat)

PASO 5: BÃšSQUEDA HÃBRIDA
------------------------
Cuando el usuario hace una pregunta, se realizan DOS bÃºsquedas:

BÃšSQUEDA SEMÃNTICA (VECTOR):
- Se genera embedding de la pregunta
- Se buscan los vectores mÃ¡s cercanos
- Encuentra: "similar en significado"

BÃšSQUEDA POR PALABRAS CLAVE (TSVECTOR):
- Se usa Full-Text Search de PostgreSQL
- Se buscan coincidencias de tÃ©rminos
- Encuentra: "exactamente estas palabras"

Â¿POR QUÃ‰ HÃBRIDA?
- SemÃ¡ntica: entiende sinÃ³nimos y contexto
- Keywords: encuentra tÃ©rminos tÃ©cnicos exactos

FUSIÃ“N DE RESULTADOS:
- Se combinan ambos rankings
- Se eliminan duplicados
- Se normaliza la puntuaciÃ³n

PASO 6: RE-RANKING CON CROSSENCODER
-----------------------------------
Â¿QUÃ‰ ES UN CROSSENCODER?
Es un modelo que evalÃºa directamente la relevancia entre una pregunta
y un documento, considerando ambos juntos.

BI-ENCODER (embeddings) vs CROSS-ENCODER:
- Bi-encoder: Genera vectores por separado, compara despuÃ©s
- Cross-encoder: Procesa pregunta+documento juntos, mÃ¡s preciso pero mÃ¡s lento

MODELO USADO: ms-marco-MiniLM-L-6-v2

PROCESO:
1. BÃºsqueda inicial retorna 20 candidatos
2. CrossEncoder evalÃºa cada par (pregunta, candidato)
3. Se reordena por puntuaciÃ³n de CrossEncoder
4. Se retornan los top 5

PASO 7: GENERACIÃ“N DE RESPUESTA
-------------------------------
Los chunks relevantes se incluyen en el prompt de la IA:

PROMPT TEMPLATE:
```
Eres un asistente acadÃ©mico. Responde basÃ¡ndote SOLO en el siguiente contexto.

CONTEXTO:
[Chunks relevantes aquÃ­]

PREGUNTA DEL USUARIO:
[Pregunta aquÃ­]

INSTRUCCIONES:
- Cita las fuentes usando [1], [2], etc.
- Si no hay informaciÃ³n suficiente, dilo claramente
- MantÃ©n un tono acadÃ©mico
```

================================================================================
6. PROVEEDORES DE INTELIGENCIA ARTIFICIAL
================================================================================

6.1 ARQUITECTURA MULTI-PROVEEDOR
--------------------------------
El sistema soporta 4 proveedores de IA con una interfaz unificada:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AIProviderManager                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  get_provider(provider_id: str) -> AIProvider  â”‚
â”‚  get_all_providers() -> List[AIProvider]        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Gemini     â”‚ â”‚   OpenAI     â”‚ â”‚  Anthropic   â”‚ ...
â”‚   Provider   â”‚ â”‚   Provider   â”‚ â”‚   Provider   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

6.2 GOOGLE GEMINI
-----------------
MODELOS: gemini-2.5-flash, gemini-2.5-pro
API: REST con streaming
CARACTERÃSTICAS:
- Contexto muy largo (hasta 1M tokens)
- Bueno en cÃ³digo y razonamiento
- Tier gratuito generoso

6.3 OPENAI
----------
MODELOS: gpt-4o-mini, gpt-4o, gpt-4-turbo
API: REST con streaming (SSE)
CARACTERÃSTICAS:
- Referencia de la industria
- Muy bueno en instrucciones complejas
- Pago por uso

6.4 ANTHROPIC CLAUDE
--------------------
MODELOS: claude-3-5-sonnet, claude-3-haiku
API: REST con streaming
CARACTERÃSTICAS:
- Muy bueno en anÃ¡lisis largo
- Respuestas mÃ¡s seguras/alineadas
- Contexto de 200K tokens




6.6 STREAMING DE RESPUESTAS
---------------------------
Todas las respuestas se generan en streaming:

Â¿QUÃ‰ ES STREAMING?
En lugar de esperar la respuesta completa, se envÃ­a token por token.

TECNOLOGÃA: Server-Sent Events (SSE)
- El servidor mantiene la conexiÃ³n abierta
- EnvÃ­a datos conforme se generan
- El frontend los muestra incrementalmente

BENEFICIOS:
- UX mejorada (respuesta aparece inmediatamente)
- Timeout evitado (conexiÃ³n activa)
- CancelaciÃ³n posible (el usuario puede parar)

================================================================================
7. BASE DE DATOS Y ALMACENAMIENTO VECTORIAL
================================================================================

7.1 POSTGRESQL
--------------
Â¿POR QUÃ‰ POSTGRESQL?
- Base de datos relacional madura y robusta
- Extensible con tipos de datos personalizados
- ACID compliant (transacciones seguras)
- Bien soportado por SQLAlchemy

7.2 PGVECTOR
------------
Â¿QUÃ‰ ES?
Es una extensiÃ³n de PostgreSQL para almacenar y buscar vectores.

INSTALACIÃ“N:
```sql
CREATE EXTENSION vector;
```

TIPO DE DATO:
```sql
embedding VECTOR(384)  -- Vector de 384 dimensiones
```

OPERACIONES:
```sql
-- Distancia coseno (mÃ¡s usado para embeddings)
SELECT * FROM documents 
ORDER BY embedding <=> query_vector  -- <=> es cosine distance
LIMIT 5;
```

7.3 ÃNDICE IVFFLAT
------------------
Â¿QUÃ‰ ES?
Es un Ã­ndice que acelera las bÃºsquedas vectoriales.

Â¿CÃ“MO FUNCIONA?
1. Divide el espacio vectorial en clusters (listas)
2. Al buscar, solo revisa los clusters mÃ¡s cercanos
3. Trade-off: velocidad vs precisiÃ³n

CREACIÃ“N:
```sql
CREATE INDEX ON documents 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

PARÃMETROS:
- lists: NÃºmero de clusters (mÃ¡s = mÃ¡s preciso, mÃ¡s lento)
- probes: Clusters a revisar en bÃºsqueda (configurable en runtime)

7.4 FULL-TEXT SEARCH
--------------------
PostgreSQL tiene bÃºsqueda de texto completa nativa.

TSVECTOR: Representa el documento como tokens normalizados
TSQUERY: Representa la consulta de bÃºsqueda

EJEMPLO:
```sql
-- Crear columna de bÃºsqueda
search_vector TSVECTOR

-- Buscar
SELECT * FROM documents
WHERE search_vector @@ to_tsquery('spanish', 'machine & learning')
```

7.5 MODELOS DE DATOS
--------------------

MODELO USER:
- id (PK)
- email (Ãºnico, indexado)
- hashed_password
- gemini_api_key (encriptada)
- ai_provider (gemini/openai/anthropic/local)
- ai_model (opcional)
- role (user/admin)
- token_usage (contador)

MODELO DOCUMENT:
- id (PK)
- content (texto del chunk)
- chunk_metadata (JSON: source_file, page, etc.)
- embedding (VECTOR 384)
- search_vector (TSVECTOR)
- owner_id (FK â†’ User)

MODELO REFRESH_TOKEN:
- id (PK)
- user_id (FK â†’ User)
- token_hash (solo hash, nunca plaintext)
- family_id (para tracking de rotaciÃ³n)
- expires_at
- is_revoked

MODELO ACTIVITY_LOG:
- id (PK)
- user_id (FK, nullable para acciones sistema)
- action (login, upload, etc.)
- details (JSON)
- ip_address
- timestamp

================================================================================
8. SISTEMA DE CACHÃ‰ CON REDIS
================================================================================

8.1 Â¿QUÃ‰ ES REDIS?
------------------
Redis es un almacÃ©n de datos en memoria, usado como:
- CachÃ© (datos leÃ­dos frecuentemente)
- Message broker (cola de mensajes para Celery)
- Pub/Sub (notificaciones en tiempo real)

8.2 CACHÃ‰ DE DOS NIVELES
------------------------
NIVEL 1: LRU en Memoria (Python)
- MÃ¡s rÃ¡pido (sin I/O de red)
- Limitado por RAM del proceso
- Se pierde al reiniciar

NIVEL 2: Redis
- Persiste entre reinicios
- Compartido entre workers
- MÃ¡s lento que memoria local

FLUJO DE CACHÃ‰:
```
1. Buscar en LRU local
   â†’ Si encontrado: retornar
2. Buscar en Redis
   â†’ Si encontrado: guardar en LRU local, retornar
3. Calcular valor (embedding, bÃºsqueda, etc.)
4. Guardar en Redis
5. Guardar en LRU local
6. Retornar
```

8.3 Â¿QUÃ‰ SE CACHEA?
-------------------
- Embeddings de queries frecuentes
- Resultados de bÃºsqueda
- ConfiguraciÃ³n de usuarios

8.4 INVALIDACIÃ“N
----------------
- TTL (Time To Live) automÃ¡tico
- InvalidaciÃ³n manual al modificar datos
- Versionado de claves para updates

================================================================================
9. PROCESAMIENTO ASÃNCRONO CON CELERY
================================================================================

9.1 Â¿QUÃ‰ ES CELERY?
-------------------
Celery es una cola de tareas distribuida para Python.
Permite ejecutar tareas en segundo plano sin bloquear la API.

9.2 Â¿POR QUÃ‰ ES NECESARIO?
--------------------------
Procesar un documento PDF puede tomar 30+ segundos:
- Extraer texto
- Dividir en chunks
- Generar embeddings
- Guardar en base de datos

Sin Celery: El usuario espera bloqueado 30 segundos
Con Celery: La API responde inmediatamente, proceso en background

9.3 ARQUITECTURA
----------------
```
[Usuario] â†’ [API] â†’ [Redis Queue] â†’ [Celery Worker] â†’ [Database]
              â†“                            â†“
         Respuesta                    NotificaciÃ³n
         inmediata                    vÃ­a WebSocket
```

9.4 TAREAS IMPLEMENTADAS
------------------------
- process_document: ExtracciÃ³n y embedding de documentos
- cleanup_expired_tokens: Limpieza de tokens expirados

9.5 BROKER Y BACKEND
--------------------
BROKER: Redis (cola de tareas pendientes)
BACKEND: Redis (resultados de tareas)

================================================================================
10. FRONTEND: NEXT.JS Y REACT
================================================================================

10.1 Â¿QUÃ‰ ES NEXT.JS?
---------------------
Next.js es un framework de React que aÃ±ade:
- Server-Side Rendering (SSR)
- Static Site Generation (SSG)
- Routing basado en archivos
- API Routes
- OptimizaciÃ³n automÃ¡tica

10.2 Â¿POR QUÃ‰ NEXT.JS 15?
-------------------------
- App Router (estructura moderna)
- React Server Components
- Turbopack (bundler mÃ¡s rÃ¡pido)
- Mejor rendimiento

10.3 ESTRUCTURA DEL FRONTEND
----------------------------
frontend-react/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/                    # PÃ¡ginas (App Router)
â”‚   â”‚   â”œâ”€â”€ page.tsx            # PÃ¡gina principal
â”‚   â”‚   â”œâ”€â”€ layout.tsx          # Layout global
â”‚   â”‚   â””â”€â”€ globals.css         # Estilos globales
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ chat/               # Componentes de chat
â”‚   â”‚   â”‚   â”œâ”€â”€ chat-layout.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ chat-messages.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ chat-input.tsx
â”‚   â”‚   â”‚   â””â”€â”€ mermaid-diagram.tsx
â”‚   â”‚   â”œâ”€â”€ copilot/            # Editor LaTeX
â”‚   â”‚   â”‚   â””â”€â”€ copilot-editor.tsx
â”‚   â”‚   â””â”€â”€ ui/                 # Componentes base (Shadcn)
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ api-client.ts       # Cliente HTTP
â”‚   â”‚   â”œâ”€â”€ schemas.ts          # ValidaciÃ³n Zod
â”‚   â”‚   â””â”€â”€ hooks/              # Custom hooks
â”‚   â””â”€â”€ context/
â”‚       â””â”€â”€ auth-context.tsx    # Estado de autenticaciÃ³n
â””â”€â”€ public/                     # Assets estÃ¡ticos

10.4 COMPONENTES UI (SHADCN)
----------------------------
Shadcn/ui es una colecciÃ³n de componentes:
- Construidos sobre Radix UI (accesibilidad)
- Estilizados con Tailwind CSS
- Copiados al proyecto (no instalados como dependencia)

COMPONENTES USADOS:
- Button, Input, Dialog, Dropdown
- Toast (notificaciones)
- Accordion, Tabs
- ScrollArea, Progress

10.5 VALIDACIÃ“N CON ZOD
-----------------------
Zod es una librerÃ­a de validaciÃ³n de esquemas TypeScript-first.

EJEMPLO:
```typescript
const ChatMessageSchema = z.object({
  role: z.enum(['user', 'ai']),
  content: z.string().min(1),
  source: z.string().nullable().optional()
});

// Uso
const message = ChatMessageSchema.parse(data); // Lanza error si invÃ¡lido
```

10.6 CLIENTE API CON RETRY
--------------------------
El api-client.ts implementa:
- Retry automÃ¡tico con backoff exponencial
- Refresh token automÃ¡tico en 401
- Manejo centralizado de errores

BACKOFF EXPONENCIAL:
Intento 1: esperar 1s
Intento 2: esperar 2s
Intento 3: esperar 4s
...con jitter (variaciÃ³n aleatoria) para evitar thundering herd

================================================================================
11. SISTEMA DE AUTENTICACIÃ“N Y SEGURIDAD
================================================================================

11.1 FLUJO DE AUTENTICACIÃ“N
---------------------------
```
[Login] â†’ [Backend valida credenciales]
             â†“
[Genera Access Token (30 min) + Refresh Token (7 dÃ­as)]
             â†“
[Frontend almacena tokens]
             â†“
[Cada request incluye Access Token en header]
             â†“
[Al expirar Access Token, usa Refresh Token para obtener nuevo par]
```

11.2 JWT (JSON WEB TOKENS)
--------------------------
Â¿QUÃ‰ ES UN JWT?
Es un token que contiene informaciÃ³n codificada y firmada.

ESTRUCTURA:
```
header.payload.signature

Header: {"alg": "HS256", "typ": "JWT"}
Payload: {"sub": "user@email.com", "exp": 1702648800, ...}
Signature: HMAC-SHA256(header + payload, secret_key)
```

CONTENIDO DEL PAYLOAD:
- sub: identificador del usuario (email)
- exp: timestamp de expiraciÃ³n
- role: rol del usuario

11.3 REFRESH TOKENS
-------------------
Â¿POR QUÃ‰ REFRESH TOKENS?
- Access tokens cortos (30 min) limitan el daÃ±o si se roban
- Refresh tokens largos (7 dÃ­as) evitan re-login frecuente
- RotaciÃ³n: cada uso del refresh token genera uno nuevo

SEGURIDAD:
- Token NUNCA se almacena en plaintext (solo hash SHA-256)
- Family tracking: si un token se reusa, toda la familia se revoca
- Permite "logout everywhere"

11.4 ENCRIPTACIÃ“N DE API KEYS
-----------------------------
Las API keys de los usuarios se encriptan antes de guardar:

ALGORITMO: Fernet (simÃ©trico)
- Basado en AES-128-CBC
- Incluye HMAC para integridad
- Key derivada con PBKDF2 (480,000 iteraciones)

FLUJO:
```
API Key del usuario â†’ Fernet.encrypt() â†’ Texto encriptado â†’ Base de datos
Base de datos â†’ Texto encriptado â†’ Fernet.decrypt() â†’ API Key original
```

11.5 RATE LIMITING
------------------
Limita peticiones por usuario/IP para prevenir abuso.

LÃMITES POR ROL:
- AnÃ³nimo: 30 req/min
- Usuario autenticado: 100 req/min
- Administrador: 1000 req/min

IMPLEMENTACIÃ“N: SlowAPI (basado en limits)

11.6 SECURITY HEADERS
---------------------
Middleware que aÃ±ade headers de seguridad:
- X-Content-Type-Options: nosniff
- X-Frame-Options: DENY
- Content-Security-Policy
- Strict-Transport-Security (HSTS)

11.7 AUDITORÃA
--------------
Se registran todas las acciones sensibles:
- Login exitoso/fallido
- Cambios de contraseÃ±a
- Cambios de API key
- Operaciones administrativas
- EliminaciÃ³n de documentos

================================================================================
12. EDITOR LATEX CON MONACO
================================================================================

12.1 Â¿QUÃ‰ ES MONACO EDITOR?
---------------------------
Monaco es el editor que usa VS Code, disponible como componente web.

CARACTERÃSTICAS:
- Syntax highlighting para 50+ lenguajes
- Autocompletado inteligente
- BÃºsqueda y reemplazo con regex
- MÃºltiples cursores
- Minimap

12.2 INTEGRACIÃ“N EN REACT
-------------------------
Se usa @monaco-editor/react para integrar Monaco en el proyecto.

CONFIGURACIÃ“N:
```typescript
<Editor
  height="100%"
  defaultLanguage="latex"
  theme="vs-dark"
  value={text}
  onChange={(value) => setText(value)}
  onMount={handleEditorDidMount}
  options={{
    minimap: { enabled: false },
    fontSize: 14,
    wordWrap: 'on',
    automaticLayout: true,
  }}
/>
```

12.3 AUTOCOMPLETADO LATEX
-------------------------
Se registran 80+ snippets de comandos LaTeX:

EJEMPLO DE SNIPPET:
```typescript
{
  label: '\\begin{equation}',
  insertText: '\\begin{equation}\n\t${1:contenido}\n\\end{equation}',
  documentation: 'Crea un entorno de ecuaciÃ³n numerada'
}
```

12.4 ACCIONES CONTEXTUALES
--------------------------
Al hacer clic derecho sobre texto seleccionado:
- âœ¨ Mejorar RedacciÃ³n (AcadÃ©mico)
- ğŸ‡ºğŸ‡¸ Traducir a InglÃ©s
- ğŸ”§ Corregir CÃ³digo LaTeX
- ğŸ“ Resumir SecciÃ³n
- ğŸ“š Expandir PÃ¡rrafo

Cada acciÃ³n envÃ­a el texto + instrucciÃ³n a la IA y reemplaza la selecciÃ³n.

12.5 COMPILACIÃ“N PDF
--------------------
El texto LaTeX se envÃ­a al backend, que usa un servicio de compilaciÃ³n
para generar el PDF. El PDF se muestra usando react-pdf.

================================================================================
13. CONTENEDORIZACIÃ“N CON DOCKER
================================================================================

13.1 Â¿QUÃ‰ ES DOCKER?
--------------------
Docker empaqueta aplicaciones en "contenedores" que incluyen:
- CÃ³digo de la aplicaciÃ³n
- Dependencias
- ConfiguraciÃ³n del sistema operativo
- Variables de entorno

BENEFICIO: "Works on my machine" â†’ "Works everywhere"

13.2 DOCKER COMPOSE
-------------------
Docker Compose orquesta mÃºltiples contenedores como un sistema.

SERVICIOS DEFINIDOS:
```yaml
services:
  db:         # PostgreSQL + pgvector
  cache:      # Redis
  backend:    # FastAPI
  frontend:   # Next.js
  celery_worker:  # Procesamiento async

```

13.3 HEALTH CHECKS
------------------
Cada servicio define cÃ³mo verificar que estÃ¡ funcionando:

```yaml
healthcheck:
  test: ["CMD", "pg_isready", "-U", "admin"]
  interval: 10s
  timeout: 5s
  retries: 5
```

13.4 DEPENDENCIAS ENTRE SERVICIOS
---------------------------------
```yaml
backend:
  depends_on:
    db:
      condition: service_healthy
    cache:
      condition: service_healthy
```

Esto garantiza que el backend no inicie hasta que DB y Redis estÃ©n listos.

13.5 VOLÃšMENES
--------------
Datos persistentes que sobreviven reinicios:
- postgres_data: Base de datos
- redis_data: CachÃ© persistente


13.6 NETWORKING
---------------
Todos los servicios comparten una red interna (chatbot_network).
Pueden comunicarse por nombre de servicio (ej: db:5432).

================================================================================
14. TESTING Y CALIDAD DE CÃ“DIGO
================================================================================

14.1 TESTING EN BACKEND (PYTEST)
--------------------------------
8 archivos de test con 60+ tests:

test_ai_providers.py:
- Verifica cada proveedor genera respuestas
- Verifica streaming funciona
- Verifica manejo de errores de API

test_search_engine.py:
- Verifica bÃºsqueda semÃ¡ntica
- Verifica bÃºsqueda por keywords
- Verifica fusiÃ³n de resultados
- Verifica re-ranking

test_auth.py:
- Verifica registro de usuarios
- Verifica login/logout
- Verifica tokens JWT
- Verifica refresh token rotation

test_encryption.py:
- Verifica encriptaciÃ³n/desencriptaciÃ³n de API keys
- Verifica detecciÃ³n de datos encriptados
- Verifica manejo de keys invÃ¡lidas

test_audit_service.py:
- Verifica registro de acciones
- Verifica filtrado por usuario/acciÃ³n
- Verifica paginaciÃ³n

14.2 TESTING EN FRONTEND (JEST)
-------------------------------
Tests unitarios para componentes React.

EJEMPLO:
```typescript
describe('ChatInput', () => {
  it('should submit message on Enter', () => {
    const onSubmit = jest.fn();
    render(<ChatInput onSubmit={onSubmit} />);
    
    fireEvent.change(screen.getByRole('textbox'), {
      target: { value: 'Hello' }
    });
    fireEvent.keyDown(screen.getByRole('textbox'), { key: 'Enter' });
    
    expect(onSubmit).toHaveBeenCalledWith('Hello');
  });
});
```

14.3 EJECUTAR TESTS
-------------------
Backend:
```bash
cd backend
pytest tests/ -v
```

Frontend:
```bash
cd frontend-react
npm test
```

================================================================================
15. MÃ‰TRICAS Y OBSERVABILIDAD
================================================================================

15.1 PROMETHEUS METRICS
-----------------------
Se exponen mÃ©tricas en formato Prometheus:

ENDPOINT: GET /metrics

MÃ‰TRICAS DISPONIBLES:
- chatbot_requests_total: Total de requests por endpoint
- chatbot_request_duration_seconds: Latencia (histograma)
- chatbot_ai_requests_total: Requests a proveedores IA
- chatbot_ai_tokens_total: Tokens consumidos
- chatbot_documents_processed_total: Documentos procesados
- chatbot_cache_operations_total: Hits/misses de cachÃ©

15.2 LOGGING ESTRUCTURADO
-------------------------
Los logs usan formato JSON en producciÃ³n:

```json
{
  "timestamp": "2024-12-15T10:30:45.123Z",
  "level": "INFO",
  "logger": "services.search_engine",
  "message": "Search completed",
  "query": "machine learning",
  "results_count": 5,
  "duration_ms": 234
}
```

15.3 HEALTH CHECK
-----------------
ENDPOINT: GET /health

RESPUESTA:
```json
{
  "status": "healthy",
  "version": "4.1.1"
}
```

================================================================================
16. GLOSARIO DE TÃ‰RMINOS TÃ‰CNICOS
================================================================================

API (Application Programming Interface):
Conjunto de definiciones y protocolos para comunicaciÃ³n entre software.

Async/Await:
Sintaxis para programaciÃ³n asÃ­ncrona que permite esperar operaciones sin bloquear.

Bearer Token:
Tipo de autenticaciÃ³n donde el token se envÃ­a en el header Authorization.

CORS (Cross-Origin Resource Sharing):
Mecanismo de seguridad que permite peticiones entre diferentes dominios.

Embedding:
RepresentaciÃ³n vectorial numÃ©rica del significado semÃ¡ntico de un texto.

FastAPI:
Framework web moderno para Python, basado en type hints y alto rendimiento.

Fernet:
Esquema de encriptaciÃ³n simÃ©trica que garantiza confidencialidad e integridad.

IVFFlat:
Tipo de Ã­ndice para bÃºsqueda vectorial que agrupa vectores en clusters.

JWT (JSON Web Token):
EstÃ¡ndar para tokens de autenticaciÃ³n que contienen informaciÃ³n codificada.

Middleware:
CÃ³digo que se ejecuta entre la recepciÃ³n de una peticiÃ³n y su procesamiento.

ORM (Object-Relational Mapping):
TÃ©cnica que permite interactuar con bases de datos usando objetos.

Pub/Sub (Publish/Subscribe):
PatrÃ³n de mensajerÃ­a donde emisores y receptores no se conocen directamente.

RAG (Retrieval-Augmented Generation):
TÃ©cnica que combina bÃºsqueda de informaciÃ³n con generaciÃ³n de texto por IA.

Rate Limiting:
LimitaciÃ³n del nÃºmero de peticiones que un cliente puede hacer en un tiempo.

Redis:
AlmacÃ©n de datos en memoria usado como cachÃ© y message broker.

REST (Representational State Transfer):
Arquitectura para diseÃ±o de APIs web.

SHA-256:
Algoritmo de hash criptogrÃ¡fico que produce un digest de 256 bits.

SQLAlchemy:
Biblioteca Python para interactuar con bases de datos relacionales.

SSE (Server-Sent Events):
TecnologÃ­a para que el servidor envÃ­e datos al cliente en tiempo real.

Strategy Pattern:
PatrÃ³n de diseÃ±o que permite seleccionar algoritmos en tiempo de ejecuciÃ³n.

TSVECTOR:
Tipo de dato de PostgreSQL para bÃºsqueda de texto completo.

TypeScript:
Superset de JavaScript que aÃ±ade tipado estÃ¡tico.

Vector Database:
Base de datos optimizada para almacenar y buscar vectores numÃ©ricos.

WebSocket:
Protocolo de comunicaciÃ³n bidireccional en tiempo real sobre TCP.

================================================================================
FIN DEL DOCUMENTO
================================================================================

Documento preparado para defensa de tesis.
VersiÃ³n: 4.1.1
Fecha: Diciembre 2024

Para consultas adicionales sobre cualquier aspecto tÃ©cnico, referirse al cÃ³digo
fuente o a la documentaciÃ³n oficial de cada tecnologÃ­a mencionada.
